<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Real-Time Object Detection</title>

<!-- ONNX Runtime Web -->
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.0/dist/ort.min.js"></script>

<style>
* {
  box-sizing: border-box;
  margin: 0;
  padding: 0;
}

body {
  font-family: Arial, sans-serif;
  background: linear-gradient(135deg, #f0f4f8, #d9e2ec);
  min-height: 100vh;
  padding: 50px 20px;
  text-align: center;
}

h1 {
  letter-spacing: 4px;
  margin-bottom: 20px;
  color: #334e68;
}

.controls {
  margin-bottom: 30px;
}

button {
  background: linear-gradient(135deg, #86c8bc, #52b69a);
  color: #fff;
  border: none;
  border-radius: 30px;
  padding: 12px 28px;
  font-size: 16px;
  margin: 0 8px;
  cursor: pointer;
}

button:hover {
  background: linear-gradient(135deg, #52b69a, #38a3a5);
}

.main {
  display: flex;
  justify-content: center;
  gap: 25px;
  flex-wrap: wrap;
}

.box {
  width: 420px;
  height: 320px;
  background: white;
  border-radius: 18px;
  padding: 10px;
  box-shadow: 0 10px 30px rgba(0,0,0,0.1);
}

video, canvas {
  width: 100%;
  height: 100%;
  border-radius: 14px;
  object-fit: cover;
  background: black;
}

footer {
  margin-top: 30px;
  color: #6e7e85;
}
</style>
</head>

<body>

<h1>REAL-TIME OBJECT DETECTION</h1>

<div class="controls">
  <button id="startBtn">Start Detection</button>
  <button id="stopBtn">Stop Detection</button>
</div>

<div class="main">
  <div class="box">
    <video id="video" autoplay muted playsinline></video>
  </div>
  <div class="box">
    <canvas id="canvas"></canvas>
  </div>
</div>

<footer>Â© 2025 YOLOv8 Object Detection</footer>

<script>
const startBtn = document.getElementById("startBtn");
const stopBtn  = document.getElementById("stopBtn");
const video    = document.getElementById("video");
const canvas   = document.getElementById("canvas");
const ctx      = canvas.getContext("2d");

let stream = null;
let running = false;
let rafId = null;
let session = null;
let detecting = false;

const COCO_CLASSES = [
  'person','bicycle','car','motorcycle','airplane','bus','train','truck','boat',
  'traffic light','fire hydrant','stop sign','parking meter','bench','bird','cat',
  'dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack',
  'umbrella','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball',
  'kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket',
  'bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple',
  'sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair',
  'couch','potted plant','bed','dining table','toilet','tv','laptop','mouse',
  'remote','keyboard','cell phone','microwave','oven','toaster','sink',
  'refrigerator','book','clock','vase','scissors','teddy bear','hair drier',
  'toothbrush'
];

async function loadModel() {
  if (!session) {
    session = await ort.InferenceSession.create("/static/yolov8n.onnx", {
      executionProviders: ["wasm"]
    });
    console.log("YOLOv8 model loaded");
  }
}

async function startCamera() {
  stream = await navigator.mediaDevices.getUserMedia({ video: true });
  video.srcObject = stream;
  await video.play();

  canvas.width  = video.videoWidth;
  canvas.height = video.videoHeight;

  await loadModel();
}

function preprocess() {
  const tCanvas = document.createElement("canvas");
  tCanvas.width = tCanvas.height = 640;
  const tCtx = tCanvas.getContext("2d");
  tCtx.drawImage(video, 0, 0, 640, 640);
  const img = tCtx.getImageData(0, 0, 640, 640).data;

  const input = new Float32Array(3 * 640 * 640);
  for (let i = 0, j = 0; i < img.length; i += 4, j++) {
    input[j] = img[i] / 255;
    input[j + 640*640] = img[i+1] / 255;
    input[j + 2*640*640] = img[i+2] / 255;
  }
  return input;
}

async function detect() {
  if (detecting) return [];
  detecting = true;

  try {
    const tensor = new ort.Tensor("float32", preprocess(), [1,3,640,640]);
    const output = await session.run({ images: tensor });
    const data = output[Object.keys(output)[0]].data;

    const results = [];
    for (let i = 0; i < 8400; i++) {
      const score = data[4 * 8400 + i];
      if (score > 0.4) {
        const cx = data[i];
        const cy = data[8400 + i];
        const w  = data[2*8400 + i];
        const h  = data[3*8400 + i];

        results.push({
          x: (cx - w/2) * canvas.width / 640,
          y: (cy - h/2) * canvas.height / 640,
          w: w * canvas.width / 640,
          h: h * canvas.height / 640,
          label: "object",
          score
        });
      }
    }
    return results.slice(0, 10);
  } finally {
    detecting = false;
  }
}

async function loop() {
  if (!running) return;

  ctx.clearRect(0,0,canvas.width,canvas.height);
  ctx.drawImage(video,0,0,canvas.width,canvas.height);

  const detections = await detect();
  ctx.strokeStyle = "lime";
  ctx.lineWidth = 2;

  detections.forEach(d => {
    ctx.strokeRect(d.x,d.y,d.w,d.h);
    ctx.fillText(`${d.label} ${(d.score*100).toFixed(1)}%`, d.x, d.y - 5);
  });

  rafId = requestAnimationFrame(loop);
}

startBtn.onclick = async () => {
  if (running) return;
  await startCamera();
  running = true;
  loop();
};

stopBtn.onclick = () => {
  running = false;
  if (rafId) cancelAnimationFrame(rafId);
  if (stream) stream.getTracks().forEach(t => t.stop());
  ctx.clearRect(0,0,canvas.width,canvas.height);
};
</script>

</body>
</html>
