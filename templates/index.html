<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>YOLOv8 Real-Time Object Detection</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.0/dist/ort.min.js"></script>
  <style>
    /* Kept your original UI styles [cite: 2-39] */
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
      min-height: 100vh; height: auto; display: flex; flex-direction: column; align-items: center; justify-content: flex-start;
      padding: 60px 20px 40px 20px; color: #4a4a4a; background: linear-gradient(135deg, #f0f4f8, #d9e2ec);
      position: relative; overflow-x: hidden;
    }
    h1 { font-size: 2.8rem; font-weight: 700; color: #334e68; margin-bottom: 1rem; text-align: center; letter-spacing: 0.12em; text-transform: uppercase; }
    .controls { text-align: center; margin-bottom: 32px; }
    button {
      background: linear-gradient(135deg, #86c8bc, #52b69a); color: #f0f4f8; border: none; border-radius: 999px;
      padding: 10px 24px; font-size: 1rem; font-weight: 600; margin: 0 6px; cursor: pointer;
      transition: all 0.3s ease; box-shadow: 0 6px 18px rgba(82, 182, 154, 0.6);
    }
    button:hover { transform: translateY(-2px) scale(1.05); background: linear-gradient(135deg, #52b69a, #38a3a5); }
    
    .main-content { display: flex; flex-direction: row; gap: 28px; justify-content: center; align-items: flex-start; width: 100%; max-width: 960px; }
    .box {
      flex: 1; aspect-ratio: 1/1; position: relative; border-radius: 20px; background: rgba(255, 255, 255, 0.75);
      border: 1.5px solid rgba(132, 196, 191, 0.7); box-shadow: 0 12px 40px rgba(95, 178, 167, 0.26);
      backdrop-filter: blur(16px); display: flex; align-items: center; justify-content: center; overflow: hidden;
    }
    video, canvas { width: 100%; height: 100%; border-radius: 18px; object-fit: cover; z-index: 1; }

    /* Added Stats Display - Matches your theme [cite: 22, 23] */
    .stats-overlay {
      position: absolute; top: 10px; left: 10px; z-index: 10;
      background: rgba(255, 255, 255, 0.85); padding: 10px 15px;
      border-radius: 12px; border: 1px solid rgba(82, 182, 154, 0.5);
      font-size: 0.85rem; color: #334e68; pointer-events: none;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
    .stats-overlay b { color: #52b69a; }

    footer { margin-top: 36px; text-align: center; font-size: 0.92rem; color: #6e7e85; padding-bottom: 20px; }

    @media (max-width: 900px) {
      .main-content { flex-direction: column; align-items: center; }
      .box { width: 90vw; aspect-ratio: 4/3; }
    }
  </style>
</head>
<body>
  <h1>REAL-TIME OBJECT DETECTION</h1>
  <div class="controls">
    <button id="start">Start Detection</button>
    <button id="stop">Stop Detection</button>
  </div>
  <div class="main-content">
    <div class="box" id="input-cam">
      <video id="video" autoplay playsinline muted></video>
    </div>
    <div class="box" id="output-cam">
      <div id="stats" class="stats-overlay" style="display:none;">
        <div>Objects: <b id="count">0</b></div>
        <div id="desc" style="margin-top:5px; font-size: 0.75rem; max-height: 100px; overflow-y: auto;"></div>
      </div>
      <canvas id="canvas"></canvas>
    </div>
  </div>
  <footer>&copy; 2025 YOLOv8 Detection Demo</footer>

  <script>
    const startBtn = document.getElementById('start');
    const stopBtn = document.getElementById('stop');
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const statsOverlay = document.getElementById('stats');
    const countEl = document.getElementById('count');
    const descEl = document.getElementById('desc');

    let stream = null;
    let running = false;
    let rafId = null;
    let session = null;
    let isDetecting = false;

    const COCO_CLASSES = ['person','bicycle','car','motorcycle','airplane','bus','train','truck','boat','traffic light','fire hydrant','stop sign','parking meter','bench','bird','cat','dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack','umbrella','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball','kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket','bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple','sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair','couch','potted plant','bed','dining table','toilet','tv','laptop','mouse','remote','keyboard','cell phone','microwave','oven','toaster','sink','refrigerator','book','clock','vase','scissors','teddy bear','hair drier','toothbrush'];

    async function initModel() {
      if (!session) {
        try {
          // Note: Ensure this path is correct for your local setup [cite: 44]
          session = await ort.InferenceSession.create('/static/yolov8n.onnx', { executionProviders: ['wasm'] });
          console.log('Model loaded');
        } catch (e) {
          console.error(e);
          // Fallback to a CDN if local fails (optional)
          alert("Model file not found at /static/yolov8n.onnx. Please check your folder structure.");
        }
      }
    }

    function preprocess() {
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = tempCanvas.height = 640;
      const tCtx = tempCanvas.getContext('2d');
      tCtx.drawImage(video, 0, 0, 640, 640);
      const data = tCtx.getImageData(0, 0, 640, 640).data;
      const input = new Float32Array(3 * 640 * 640);
      for (let i = 0, j = 0; i < data.length; i += 4, j++) {
        input[j] = data[i]/255; 
        input[j + 409600] = data[i+1]/255; 
        input[j + 819200] = data[i+2]/255;
      }
      return input;
    }

    async function detect() {
      if (isDetecting || !session) return [];
      isDetecting = true;
      try {
        const tensor = new ort.Tensor('float32', preprocess(), [1, 3, 640, 640]);
        const output = await session.run({ images: tensor });
        return postprocess(output[Object.keys(output)[0]]);
      } finally { isDetecting = false; }
    }

    function postprocess(out) {
      const detections = [];
      const data = out.data;
      // Standard YOLOv8 post-processing for 8400 boxes [cite: 58-71]
      for (let i = 0; i < 8400; i++) {
        let maxS = 0, id = -1;
        for (let c = 0; c < 80; c++) {
          let s = data[(4 + c) * 8400 + i];
          if (s > maxS) { maxS = s; id = c; }
        }
        if (maxS > 0.4) {
          const sw = canvas.width / 640, sh = canvas.height / 640;
          detections.push({
            label: COCO_CLASSES[id], score: maxS,
            x: (data[i] - data[2*8400+i]/2) * sw,
            y: (data[8400+i] - data[3*8400+i]/2) * sh,
            w: data[2*8400+i] * sw, h: data[3*8400+i] * sh
          });
        }
      }
      return detections.slice(0, 10);
    }

    async function loop() {
      if (!running) return;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const results = await detect();
      
      // Update Object Count and Description [cite: 87, 90]
      countEl.innerText = results.length;
      descEl.innerHTML = results.map(r => `${r.label} (${Math.round(r.w)}x${Math.round(r.h)}px)`).join('<br>');

      results.forEach(r => {
        ctx.strokeStyle = 'rgba(82, 182, 154, 0.9)';
        ctx.lineWidth = 3;
        ctx.strokeRect(r.x, r.y, r.w, r.h);
        ctx.fillStyle = 'rgba(82, 182, 154, 0.9)';
        ctx.fillRect(r.x, r.y - 25, ctx.measureText(r.label).width + 10, 25);
        ctx.fillStyle = '#fff';
        ctx.fillText(`${r.label} ${Math.round(r.score*100)}%`, r.x + 5, r.y - 7);
      });
      rafId = requestAnimationFrame(loop);
    }

    // Button Logic - Fixed [cite: 93-99]
    startBtn.onclick = async () => {
      if (running) return;
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        await video.play();
        canvas.width = video.videoWidth; 
        canvas.height = video.videoHeight;
        await initModel();
        running = true;
        statsOverlay.style.display = 'block';
        loop();
      } catch (e) { alert("Camera access failed."); }
    };

    stopBtn.onclick = () => {
      running = false;
      if (rafId) cancelAnimationFrame(rafId);
      if (stream) stream.getTracks().forEach(t => t.stop());
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      statsOverlay.style.display = 'none';
    };
  </script>
</body>
</html>
