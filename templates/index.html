<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Real-Time Object Detection</title>

<!-- ONNX Runtime Web -->
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.0/dist/ort.min.js"></script>

<style>
* {
  box-sizing: border-box;
  margin: 0;
  padding: 0;
}
body {
  font-family: Arial, sans-serif;
  background: linear-gradient(135deg, #f0f4f8, #d9e2ec);
  min-height: 100vh;
  padding: 50px 20px;
  text-align: center;
}
h1 {
  letter-spacing: 4px;
  margin-bottom: 20px;
  color: #334e68;
}
.controls {
  margin-bottom: 30px;
}
button {
  background: linear-gradient(135deg, #86c8bc, #52b69a);
  color: #fff;
  border: none;
  border-radius: 30px;
  padding: 12px 28px;
  font-size: 16px;
  margin: 0 8px;
  cursor: pointer;
}
button:hover {
  background: linear-gradient(135deg, #52b69a, #38a3a5);
}
.main {
  display: flex;
  justify-content: center;
  gap: 25px;
  flex-wrap: wrap;
}
.box {
  width: 420px;
  height: 320px;
  background: white;
  border-radius: 18px;
  padding: 10px;
  box-shadow: 0 10px 30px rgba(0,0,0,0.1);
}
video, canvas {
  width: 100%;
  height: 100%;
  border-radius: 14px;
  object-fit: cover;
  background: black;
}
footer {
  margin-top: 30px;
  color: #6e7e85;
}
</style>
</head>
<body>

<h1>REAL-TIME OBJECT DETECTION</h1>

<div class="controls">
  <button id="startBtn">Start Detection</button>
  <button id="stopBtn">Stop Detection</button>
</div>

<div class="main">
  <div class="box">
    <video id="video" autoplay muted playsinline></video>
  </div>
  <div class="box">
    <canvas id="canvas"></canvas>
  </div>
</div>

<footer>Â© 2025 YOLOv8 Object Detection</footer>

<script>
const startBtn = document.getElementById("startBtn");
const stopBtn  = document.getElementById("stopBtn");
const video    = document.getElementById("video");
const canvas   = document.getElementById("canvas");
const ctx      = canvas.getContext("2d");

let stream = null;
let running = false;
let rafId = null;
let session = null;
let detecting = false;

// COCO classes
const COCO_CLASSES = [
  'person','bicycle','car','motorcycle','airplane','bus','train','truck','boat',
  'traffic light','fire hydrant','stop sign','parking meter','bench','bird','cat',
  'dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack',
  'umbrella','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball',
  'kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket',
  'bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple',
  'sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair',
  'couch','potted plant','bed','dining table','toilet','tv','laptop','mouse',
  'remote','keyboard','cell phone','microwave','oven','toaster','sink',
  'refrigerator','book','clock','vase','scissors','teddy bear','hair drier',
  'toothbrush'
];

async function loadModel() {
  if (!session) {
    try {
      session = await ort.InferenceSession.create("/static/yolov8n.onnx", {
        executionProviders: ["wasm"]
      });
      console.log("YOLOv8 model loaded");
    } catch (err) {
      console.error("Error loading model:", err);
    }
  }
}

async function startCamera() {
  try {
    stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = stream;
    await video.play();
    canvas.width  = video.videoWidth;
    canvas.height = video.videoHeight;
  } catch (err) {
    console.error("Error accessing webcam:", err);
  }
}

function preprocess() {
  const tCanvas = document.createElement("canvas");
  tCanvas.width = 640;
  tCanvas.height = 640;
  const tCtx = tCanvas.getContext("2d");
  tCtx.drawImage(video, 0, 0, 640, 640);
  const imgData = tCtx.getImageData(0, 0, 640, 640);
  const img = imgData.data;

  const input = new Float32Array(3 * 640 * 640);
  let index = 0;
  for (let i = 0; i < img.length; i += 4) {
    input[index++] = img[i] / 255;
    input[index++] = img[i + 1] / 255;
    input[index++] = img[i + 2] / 255;
  }
  return input;
}

async function detect() {
  if (detecting || !session) return [];
  detecting = true;
  try {
    const inputTensor = new ort.Tensor("float32", preprocess(), [1, 3, 640, 640]);
    const output = await session.run({ images: inputTensor });
    const outputTensorKey = Object.keys(output)[0];
    const outputTensor = output[outputTensorKey];

    // Log shape and sample data for debugging
    console.log('Output shape:', outputTensor.shape);
    console.log('Output data sample:', outputTensor.data.slice(0, 50));

    const shape = outputTensor.shape;
    const data = outputTensor.data;

    if (!shape || !data) {
      console.error('Invalid output tensor:', outputTensor);
      return [];
    }

    // Adjust parsing based on shape
    // Example: if shape is [1, N, 6], N detections with 6 attributes
    // Or if shape is [1, 8400, 6], etc.
    let detectionsCount = shape[1]; // typically the number of detections
    let attrCount = shape[2]; // number of attributes per detection

    const results = [];
    for (let i = 0; i < detectionsCount; i++) {
      const offset = i * attrCount;
      const [cx, cy, w, h, confidence, classId] = data.slice(offset, offset + attrCount);

      if (confidence > 0.4 && classId >= 0 && classId < COCO_CLASSES.length) {
        const x = (cx - w / 2) * canvas.width;
        const y = (cy - h / 2) * canvas.height;
        const width = w * canvas.width;
        const height = h * canvas.height;
        results.push({ x, y, w: width, h: height, label: COCO_CLASSES[Math.round(classId)], score: confidence });
      }
    }
    return results;
  } catch (err) {
    console.error("Detection error:", err);
    return [];
  } finally {
    detecting = false;
  }
}

async function loop() {
  if (!running) return;

  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  const detections = await detect();
  console.log("Detections:", detections);

  ctx.strokeStyle = "lime";
  ctx.lineWidth = 2;
  ctx.font = "14px Arial";
  ctx.fillStyle = "lime";

  detections.forEach(d => {
    ctx.strokeRect(d.x, d.y, d.w, d.h);
    ctx.fillText(`${d.label} ${(d.score * 100).toFixed(1)}%`, d.x, d.y > 20 ? d.y - 5 : d.y + 15);
  });

  rafId = requestAnimationFrame(loop);
}

document.getElementById("startBtn").onclick = async () => {
  if (running) return;
  await loadModel();
  await startCamera();
  running = true;
  loop();
};

document.getElementById("stopBtn").onclick = () => {
  running = false;
  if (rafId) cancelAnimationFrame(rafId);
  if (stream) {
    stream.getTracks().forEach(t => t.stop());
    stream = null;
  }
  ctx.clearRect(0, 0, canvas.width, canvas.height);
};
</script>

</body>
</html>
