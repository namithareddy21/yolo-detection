<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>YOLOv8 Real-Time Object Detection</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.0/dist/ort.min.js"></script>
  <style>
    /* UI styles maintained from source [cite: 2-39] */
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
      min-height: 100vh; display: flex; flex-direction: column; align-items: center;
      padding: 60px 20px 40px 20px; color: #4a4a4a; background: linear-gradient(135deg, #f0f4f8, #d9e2ec);
      overflow-x: hidden; position: relative;
    }
    h1 { font-size: 2.8rem; font-weight: 700; color: #334e68; margin-bottom: 1rem; text-align: center; letter-spacing: 0.12em; text-transform: uppercase; }
    .controls { text-align: center; margin-bottom: 32px; }
    button {
      background: linear-gradient(135deg, #86c8bc, #52b69a); color: #f0f4f8; border: none; border-radius: 999px;
      padding: 10px 24px; font-size: 1rem; font-weight: 600; margin: 0 6px; cursor: pointer; transition: 0.3s;
      box-shadow: 0 6px 18px rgba(82, 182, 154, 0.6);
    }
    button:hover { transform: translateY(-2px); background: linear-gradient(135deg, #52b69a, #38a3a5); }
    .main-content { display: flex; flex-direction: row; gap: 28px; justify-content: center; align-items: flex-start; width: 100%; max-width: 960px; }
    .box {
      flex: 1; aspect-ratio: 1/1; position: relative; border-radius: 20px; background: rgba(255, 255, 255, 0.75);
      border: 1.5px solid rgba(132, 196, 191, 0.7); backdrop-filter: blur(16px); overflow: hidden;
    }
    video, canvas { width: 100%; height: 100%; border-radius: 18px; object-fit: cover; }
    
    .stats-overlay {
      position: absolute; top: 15px; left: 15px; z-index: 10;
      background: rgba(255, 255, 255, 0.9); padding: 12px; border-radius: 12px;
      border: 1px solid rgba(82, 182, 154, 0.5); font-size: 0.8rem; color: #334e68;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1); pointer-events: none;
    }
    .stats-overlay b { color: #52b69a; }
    footer { margin-top: 36px; text-align: center; font-size: 0.92rem; color: #6e7e85; }
    
    @media (max-width: 900px) {
      .main-content { flex-direction: column; align-items: center; }
      .box { width: 90vw; aspect-ratio: 4/3; }
    }
  </style>
</head>
<body>
  <h1>REAL-TIME OBJECT DETECTION</h1>
  <div class="controls">
    <button id="start">Start Detection</button>
    <button id="stop">Stop Detection</button>
  </div>
  <div class="main-content">
    <div class="box"><video id="video" autoplay playsinline muted></video></div>
    <div class="box">
      <div id="stats" class="stats-overlay" style="display:none;">
        <div>Objects: <b id="count">0</b></div>
        <div id="desc" style="margin-top:5px; max-height: 80px; overflow-y: auto;"></div>
      </div>
      <canvas id="canvas"></canvas>
    </div>
  </div>
  <footer>&copy; 2025 YOLOv8 Detection Demo</footer>

  <script>
    const startBtn = document.getElementById('start');
    const stopBtn = document.getElementById('stop');
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const statsOverlay = document.getElementById('stats');
    const countEl = document.getElementById('count');
    const descEl = document.getElementById('desc');

    let stream = null;
    let running = false;
    let session = null;
    let isDetecting = false;

    const COCO_CLASSES = ['person','bicycle','car','motorcycle','airplane','bus','train','truck','boat','traffic light','fire hydrant','stop sign','parking meter','bench','bird','cat','dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack','umbrella','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball','kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket','bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple','sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair','couch','potted plant','bed','dining table','toilet','tv','laptop','mouse','remote','keyboard','cell phone','microwave','oven','toaster','sink','refrigerator','book','clock','vase','scissors','teddy bear','hair drier','toothbrush'];

    async function initModel() {
      if (!session) {
        try {
          // Pointing to a reliable CDN model for testing
          session = await ort.InferenceSession.create('https://raw.githubusercontent.com/Hyuto/yolov8-onnxruntime-web/master/public/model/yolov8n.onnx', { executionProviders: ['wasm'] });
          console.log('Model loaded');
        } catch (e) { alert("Model load failed: " + e.message); }
      }
    }

    function preprocess() {
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = tempCanvas.height = 640;
      const tCtx = tempCanvas.getContext('2d');
      tCtx.drawImage(video, 0, 0, 640, 640);
      const data = tCtx.getImageData(0, 0, 640, 640).data;
      const input = new Float32Array(3 * 640 * 640);
      for (let i = 0, j = 0; i < data.length; i += 4, j++) {
        input[j] = data[i]/255; 
        input[j + 409600] = data[i+1]/255; 
        input[j + 819200] = data[i+2]/255;
      }
      return input;
    }

    async function detect() {
      if (isDetecting || !session || video.readyState < 2) return [];
      isDetecting = true;
      try {
        const tensor = new ort.Tensor('float32', preprocess(), [1, 3, 640, 640]);
        const output = await session.run({ images: tensor });
        return postprocess(output[Object.keys(output)[0]]);
      } catch (e) { return []; } finally { isDetecting = false; }
    }

    function postprocess(out) {
      const detections = [];
      const data = out.data;
      for (let i = 0; i < 8400; i++) {
        let maxS = 0, id = -1;
        for (let c = 0; c < 80; c++) {
          let s = data[(4 + c) * 8400 + i];
          if (s > maxS) { maxS = s; id = c; }
        }
        if (maxS > 0.45) {
          const sw = canvas.width / 640, sh = canvas.height / 640;
          detections.push({
            label: COCO_CLASSES[id], score: maxS,
            x: (data[i] - data[2*8400+i]/2) * sw,
            y: (data[8400+i] - data[3*8400+i]/2) * sh,
            w: data[2*8400+i] * sw, h: data[3*8400+i] * sh
          });
        }
      }
      return detections.slice(0, 10);
    }

    async function loop() {
      if (!running) return;
      if (video.readyState >= 2) {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        const results = await detect();
        
        countEl.innerText = results.length;
        descEl.innerHTML = results.map(r => `${r.label} (${Math.round(r.w)}x${Math.round(r.h)}px)`).join('<br>');

        results.forEach(r => {
          ctx.strokeStyle = '#52b69a';
          ctx.lineWidth = 3;
          ctx.strokeRect(r.x, r.y, r.w, r.h);
          ctx.fillStyle = '#52b69a';
          ctx.fillText(`${r.label} ${Math.round(r.score*100)}%`, r.x, r.y - 5);
        });
      }
      requestAnimationFrame(loop);
    }

    startBtn.onclick = async () => {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          video.play();
          running = true;
          statsOverlay.style.display = 'block';
          loop();
        };
        await initModel();
      } catch (e) { alert("Camera access denied or not found."); }
    };

    stopBtn.onclick = () => {
      running = false;
      if (stream) stream.getTracks().forEach(t => t.stop());
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      statsOverlay.style.display = 'none';
    };
  </script>
</body>
</html>
